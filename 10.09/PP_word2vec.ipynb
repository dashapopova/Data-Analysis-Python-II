{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "PP_word2vec.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi-d6xoVHNFs"
      },
      "source": [
        "### Distributive hypothesis in semantics\n",
        "\n",
        "+ Ludwig Wittgenstein:\n",
        "Die Bedeutung eines Wortes liegt in seinem Gebrauch.\n",
        "\n",
        "\n",
        "+ Firth (1935:37) on context dependence (cited by Stubbs):\n",
        "the complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously.\n",
        "\n",
        "\n",
        "+ Firth (1957:11):\n",
        "You shall know a word by the company it keeps . . .\n",
        "\n",
        "\n",
        "+ Harris (1954:34):\n",
        "All elements in a language can be grouped into classes whose relative occurrence can be stated exactly. However, for the occurrence of a particular member of one class relative to a particular member of another class, it would be necessary to speak in terms of probability, based on the frequency of that occurrence in a sample.\n",
        "\n",
        "\n",
        "+ Harris (1954:34):\n",
        "It is possible to state the occurrence of any element relative to any other element, to the degree of exactness indicated above, so that distributional statements can cover all of the material of a language without requiring support from other types of information.\n",
        "\n",
        "\n",
        "+ Harris (1954:34) (anticipating deep learning?):\n",
        "The restrictions on relative occurrence of each element are described most simply by a network of interrelated statements, certain of them being put in terms of the results of certain others, rather than by a simple measure of the total restriction on each element separately.\n",
        "\n",
        "\n",
        "+ Harris (1954:36) on levels of analysis:\n",
        "\n",
        "\n",
        "    - Some question has been raised as to the reality of this structure. Does it really exist, or is it just a mathematical creation of the investigator’s? Skirting the philosophical difficulties of this problem, we should, in any case, realize that there are two quite different questions here. \n",
        "    \n",
        "    - One: Does the structure really exist in language? The answer is yes, as much as any scientific structure really obtains in the data which it describes — the scientific structure states a network of relations, and these relations really hold in the data investigated.\n",
        "    \n",
        "    - Two: Does the structure really exist in speakers? Here we are faced with a question of fact which is not directly or fully investigated in the process of determining the distributional structure. Clearly, certain behaviors of the speakers indicate perception along the lines of the distributional structure, for example, the fact that while people imitate nonlinguistic or foreign-language sounds, they repeat utterances of their own language.\n",
        "\n",
        "\n",
        "+ Harris (1954:39) on meaning and context-dependence:\n",
        "All this is not to say that there is not a great interconnection between language and meaning, in whatever sense it may be possible to use this work. But it is not a one-to-one relation between morphological structure and anything else. There is not even a one-to-one relation between vocabulary and any independent classification of meaning; we cannot say that each morpheme or word has a single central meaning or even that it has a continuous or coherent range of meanings...The correlation between language and meaning is much greater when we consider connected discourse.\n",
        "\n",
        "\n",
        "+ Harris (1954:43):\n",
        "The fact that, for example, not every adjective occurs with every noun can be used as a measure of meaning difference. For it is not merely that different members of the one class have different selections of members of the other class with which they are actually found. More than that: if we consider words or morphemes A and B to be more different than A and C, then we will often find that the distributions of A and B are more different than the distributions of A and C. In other words, difference in meaning correlates with difference in distribution.\n",
        "\n",
        "\n",
        "+ Turney & Pantel (2010:153):\n",
        "\n",
        "\n",
        "    - Statistical semantics hypothesis: Statistical patterns of human word usage can be used to figure out what people mean (Weaver, 1955; Furnas et al., 1983). – If units of text have similar vectors in a text frequency matrix, then they tend to have similar meanings. (We take this to be a general hypothesis that subsumes the four more specific hypotheses that follow.)\n",
        "\n",
        "    - Bag of words hypothesis: The frequencies of words in a document tend to indicate the relevance of the document to a query (Salton et al., 1975). – If documents and pseudo-documents (queries) have similar column vectors in a term–document matrix, then they tend to have similar meanings.\n",
        "\n",
        "    - Distributional hypothesis: Words that occur in similar contexts tend to have similar meanings (Harris, 1954; Firth, 1957; Deerwester et al., 1990). – If words have similar row vectors in a word–context matrix, then they tend to have similar meanings.\n",
        "      \n",
        "    - Extended distributional hypothesis: Patterns that co-occur with similar pairs tend to have similar meanings (Lin & Pantel, 2001). – If patterns have similar column vectors in a pair–pattern matrix, then they tend to express similar semantic relations.\n",
        "\n",
        "    - Latent relation hypothesis: Pairs of words that co-occur in similar patterns tend to have similar semantic relations (Turney et al., 2003). – If word pairs have similar row vectors in a pair–pattern matrix, then they tend to have similar semantic relations.\n",
        "    \n",
        "    \n",
        "+ What is the meaning of the word \"bardiwac\" (Stefan Evert's example)?\n",
        "\n",
        "    - He handed her her glass of bardiwac.\n",
        "\n",
        "    - Beef dishes are made to complement the bardiwacs.\n",
        "\n",
        "    - Nigel staggered to his feet, face flushed from too much bardiwac.\n",
        "\n",
        "    - Malbec, one of the lesser-known bardiwac grapes, responds well to Australia’s sunshine.\n",
        "\n",
        "    - I dined off bread and cheese and this excellent bardiwac.\n",
        "\n",
        "    - The drinks were delicious: blood-red bardiwac as well as light, sweet Rhenish.\n",
        "\n",
        "#### Word2Vec\n",
        "\n",
        "One of the most famous distributional models is word2vec. The model is based on a neural network that predicts the probability of occurrence of a given word in a given context. The two seminal papers are linked below:\n",
        "\n",
        "+ [Efficient Estimation of Word Representations inVector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
        "+ [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)\n",
        "\n",
        "The model produces word representations in a form of a vector, or, an embedding.\n",
        "\n",
        "Word2Vec comprises two algorithms: Skip-Gram and Continuous Bag-Of-Words (CBOW). The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word.\n",
        "\n",
        "#### How does word2vec work?\n",
        "\n",
        "Word2Vec takes a corpus as an input and creates a vector for each word. Vectors (embeddings) are created based on the distributional hypothesis. Cosine similarity between embeddings reflects similarity in the semantics of the words.\n",
        "\n",
        "We can use embeddings to create analogies:\n",
        "\n",
        "+ king: man = queen: woman $\\Rightarrow$\n",
        "+ king - man + woman = queen\n",
        "\n",
        "![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)\n",
        "\n",
        "More on the mechanics you can find [here](https://habr.com/ru/post/446530/)\n",
        "\n",
        "#### Why do we need it?\n",
        "\n",
        "+ to solve semantic problems\n",
        "+ for which classes of words is the distributional hypothesis most useful?\n",
        "+ some papers on its use in semantics:\n",
        "\n",
        "* [Turney and Pantel 2010](https://jair.org/index.php/jair/article/view/10640)\n",
        "* [Lenci 2018](https://www.annualreviews.org/doi/abs/10.1146/annurev-linguistics-030514-125254?journalCode=linguistics)\n",
        "* [Smith 2019](https://arxiv.org/pdf/1902.06006.pdf)\n",
        "* [Pennington et al. 2014](https://www.aclweb.org/anthology/D14-1162/)\n",
        "* [Faruqui et al. 2015](https://www.aclweb.org/anthology/N15-1184/)\n",
        "\n",
        "+ to create input for neural networks\n",
        "+ word2vec is used in Siri, Google Assistant, Alexa, Google Translate...\n",
        "\n",
        "#### Gensim\n",
        "\n",
        "We will use the `gensim` library to get access to the word2vec model. Here you can find the library's [documentation](https://radimrehurek.com/gensim/models/word2vec.html).\n",
        "\n",
        "First, let's install the library: `pip install gensim`. You can do it from jupyter: `!pip install gensim`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyroE0-XHNGG"
      },
      "source": [
        "import re\n",
        "import gensim\n",
        "import logging\n",
        "import nltk.data\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import word2vec\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCVWJx4vHNGl"
      },
      "source": [
        "#### How to train your own model\n",
        "\n",
        "NB! The training does not involve preprocessing! It means that, if necessary for your task, you have to get rid of the punctuation, lower, lemmatize, do the pos tagging before the training.\n",
        "\n",
        "To log the training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dmidzjLHNGo"
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG-y6_ciHNGw"
      },
      "source": [
        "The input for the model is a text file, where every sentence starts on a new line. The text is stripped of the punctuation, lowered and lemmatized. We won't do the preprocessing part in class, we will use a preprocessed file liza_lem.txt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwkNLeTyHNGz"
      },
      "source": [
        "f = 'liza_lem.txt'\n",
        "data = gensim.models.word2vec.LineSentence(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EkuDSJjHNG2"
      },
      "source": [
        "We will be training our model now. The main parameters:\n",
        "\n",
        "+ the data should be iterable\n",
        "+ size — dimensionality of the word vectors,\n",
        "+ window — maximum distance between the current and predicted word within a sentence,\n",
        "+ min_count — ignores all words with total frequency lower than this,\n",
        "+ sg —  training algorithm: 1 for skip-gram; otherwise CBOW,\n",
        "+ sample — the threshold for configuring which higher-frequency words are randomly downsampled,\n",
        "+ iter — number of iterations (epochs) over the corpus,\n",
        "+ max_vocab_size — limits the RAM during vocabulary building; if there are more unique words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM. Set to None for no limit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGKn-5wdHNG-",
        "outputId": "95e054a8-a364-4164-8506-773415997e26"
      },
      "source": [
        "%time model_liza = gensim.models.Word2Vec(data, size=300, window=5, min_count=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-09 11:06:22,598 : INFO : collecting all words and their counts\n",
            "2021-09-09 11:06:22,603 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-09-09 11:06:22,605 : INFO : collected 1189 word types from a corpus of 3043 raw words and 1 sentences\n",
            "2021-09-09 11:06:22,608 : INFO : Loading a fresh vocabulary\n",
            "2021-09-09 11:06:22,613 : INFO : effective_min_count=2 retains 463 unique words (38% of original 1189, drops 726)\n",
            "2021-09-09 11:06:22,615 : INFO : effective_min_count=2 leaves 2317 word corpus (76% of original 3043, drops 726)\n",
            "2021-09-09 11:06:22,620 : INFO : deleting the raw counts dictionary of 1189 items\n",
            "2021-09-09 11:06:22,621 : INFO : sample=0.001 downsamples 82 most-common words\n",
            "2021-09-09 11:06:22,625 : INFO : downsampling leaves estimated 1746 word corpus (75.4% of prior 2317)\n",
            "2021-09-09 11:06:22,632 : INFO : estimated required memory for 463 words and 300 dimensions: 1342700 bytes\n",
            "2021-09-09 11:06:22,633 : INFO : resetting layer weights\n",
            "2021-09-09 11:06:22,740 : INFO : training model with 3 workers on 463 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2021-09-09 11:06:22,749 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-09 11:06:22,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-09 11:06:22,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-09 11:06:22,758 : INFO : EPOCH - 1 : training on 3043 raw words (1733 effective words) took 0.0s, 142068 effective words/s\n",
            "2021-09-09 11:06:22,769 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-09 11:06:22,773 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-09 11:06:22,776 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-09 11:06:22,777 : INFO : EPOCH - 2 : training on 3043 raw words (1763 effective words) took 0.0s, 164043 effective words/s\n",
            "2021-09-09 11:06:22,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-09 11:06:22,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-09 11:06:22,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-09 11:06:22,791 : INFO : EPOCH - 3 : training on 3043 raw words (1777 effective words) took 0.0s, 240179 effective words/s\n",
            "2021-09-09 11:06:22,807 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-09 11:06:22,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-09 11:06:22,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-09 11:06:22,826 : INFO : EPOCH - 4 : training on 3043 raw words (1752 effective words) took 0.0s, 70037 effective words/s\n",
            "2021-09-09 11:06:22,835 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-09 11:06:22,839 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-09 11:06:22,842 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-09 11:06:22,843 : INFO : EPOCH - 5 : training on 3043 raw words (1747 effective words) took 0.0s, 167793 effective words/s\n",
            "2021-09-09 11:06:22,844 : INFO : training on a 15215 raw words (8772 effective words) took 0.1s, 86227 effective words/s\n",
            "2021-09-09 11:06:22,845 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 203 ms, sys: 11.7 ms, total: 215 ms\n",
            "Wall time: 249 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ8gG5e9HNG_"
      },
      "source": [
        "We can normalize the vectors, then the model would take up less RAM. After this operation, however, you won't be able to retrain the model. L2-normalization is used: the sum of squares of all the vector elements will be brought to 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYprhwMAHNHF",
        "outputId": "e22b3f1a-1e57-4617-e3e4-201b3cfcb326"
      },
      "source": [
        "model_liza.init_sims(replace=True)\n",
        "model_path = \"liza.bin\"\n",
        "\n",
        "print(\"Saving model...\")\n",
        "model_liza.wv.save_word2vec_format(model_path, binary=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-09 11:06:42,499 : INFO : precomputing L2-norms of word weight vectors\n",
            "2021-09-09 11:06:42,513 : INFO : storing 463x300 projection weights into liza.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ2LczlgHNHJ"
      },
      "source": [
        "Let's count the number of words in the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUX-y4GwHNHP",
        "outputId": "70a3b4f5-84eb-4581-c07a-7db7aadea3ec"
      },
      "source": [
        "print(len(model_liza.wv.vocab))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4UYddmkHNHS",
        "outputId": "5900c75e-d69d-494d-8658-197afce38d38"
      },
      "source": [
        "print(sorted([w for w in model_liza.wv.vocab]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ангел', 'анюта', 'армия', 'ах', 'барин', 'бедный', 'белый', 'берег', 'березовый', 'беречь', 'бесчисленный', 'благодарить', 'бледный', 'блеснуть', 'блестящий', 'близ', 'бог', 'богатый', 'большой', 'бояться', 'брать', 'бросать', 'бросаться', 'бывать', 'важный', 'ввечеру', 'вдова', 'велеть', 'великий', 'великолепный', 'верить', 'верно', 'весело', 'веселый', 'весна', 'вести', 'весь', 'весьма', 'ветвь', 'ветер', 'вечер', 'взглядывать', 'вздох', 'вздыхать', 'взор', 'взять', 'вид', 'видеть', 'видеться', 'видный', 'вместе', 'вода', 'возвращаться', 'воздух', 'война', 'воображать', 'воображение', 'воспоминание', 'восторг', 'восхищаться', 'время', 'вслед', 'вставать', 'встречаться', 'всякий', 'высокий', 'выть', 'выходить', 'глаз', 'глубокий', 'гнать', 'говорить', 'год', 'голос', 'гора', 'горе', 'горестный', 'горлица', 'город', 'горький', 'господин', 'гром', 'грусть', 'давать', 'давно', 'далее', 'дверь', 'движение', 'двор', 'девушка', 'дело', 'день', 'деньги', 'деревня', 'деревянный', 'десять', 'добро', 'добрый', 'довольно', 'доживать', 'долго', 'должный', 'дом', 'домой', 'дочь', 'древний', 'друг', 'дуб', 'думать', 'душа', 'едва', 'ехать', 'жалобный', 'желание', 'желать', 'жениться', 'жених', 'женщина', 'жестокий', 'живой', 'жизнь', 'жить', 'забава', 'заблуждение', 'забывать', 'завтра', 'задумчивость', 'закраснеться', 'закричать', 'заря', 'здешний', 'здравствовать', 'зеленый', 'земля', 'златой', 'знать', 'ибо', 'играть', 'идти', 'имя', 'искать', 'исполняться', 'испугаться', 'история', 'исчезать', 'кабинет', 'казаться', 'капля', 'карета', 'карман', 'картина', 'катиться', 'клятва', 'колено', 'копейка', 'который', 'красота', 'крест', 'крестьянин', 'крестьянка', 'кровь', 'кроме', 'купить', 'ландыш', 'ласка', 'ласковый', 'левый', 'лес', 'лететь', 'летний', 'лето', 'лиза', 'лизин', 'лизина', 'лицо', 'лишний', 'лодка', 'ложиться', 'луг', 'луч', 'любезный', 'любить', 'любовь', 'лютый', 'матушка', 'мать', 'место', 'месяц', 'мечта', 'милый', 'мимо', 'минута', 'многочисленный', 'молить', 'молиться', 'молния', 'молодой', 'молодость', 'молчать', 'монастырь', 'море', 'москва', 'москварека', 'мочь', 'мрак', 'мрачный', 'муж', 'мысль', 'наглядеться', 'надеяться', 'надлежать', 'надобно', 'называть', 'наступать', 'натура', 'находить', 'наш', 'небесный', 'небо', 'невинность', 'невинный', 'нежели', 'нежный', 'незнакомец', 'немой', 'непорочность', 'неприятель', 'несколько', 'никакой', 'никто', 'ничто', 'новый', 'ночь', 'обижать', 'облако', 'обманывать', 'обморок', 'образ', 'обращаться', 'обстоятельство', 'объятие', 'огонь', 'однако', 'окно', 'окрестности', 'оно', 'опираться', 'описывать', 'опустеть', 'освещать', 'оставаться', 'оставлять', 'останавливать', 'останавливаться', 'отвечать', 'отдавать', 'отец', 'отечество', 'отменно', 'отрада', 'очень', 'падать', 'память', 'пастух', 'первый', 'перемениться', 'переставать', 'песня', 'петь', 'печальный', 'писать', 'питать', 'плакать', 'побежать', 'побледнеть', 'погибать', 'подавать', 'подгорюниваться', 'подле', 'подозревать', 'подымать', 'поехать', 'пойти', 'показываться', 'поклониться', 'покойный', 'покрывать', 'покрываться', 'покупать', 'полагать', 'поле', 'помнить', 'поселянин', 'последний', 'постой', 'потуплять', 'поцеловать', 'поцелуй', 'правый', 'представляться', 'прежде', 'преклонять', 'прекрасный', 'прелестный', 'приводить', 'прижимать', 'принадлежать', 'принуждать', 'природа', 'приходить', 'приятный', 'провожать', 'продавать', 'проливать', 'простой', 'просыпаться', 'проходить', 'проч', 'прощать', 'прощаться', 'пруд', 'птичка', 'пылать', 'пять', 'работа', 'работать', 'радость', 'рассказывать', 'расставаться', 'рвать', 'ребенок', 'река', 'решаться', 'робкий', 'роза', 'розовый', 'роман', 'российский', 'роща', 'рубль', 'рука', 'сажень', 'самый', 'свет', 'светиться', 'светлый', 'свидание', 'свирель', 'свободно', 'свой', 'свойство', 'сделать', 'сделаться', 'сей', 'сердечный', 'сердце', 'си', 'сидеть', 'сие', 'сиять', 'сказать', 'сказывать', 'сквозь', 'скорбь', 'скоро', 'скрываться', 'слабый', 'слеза', 'слезать', 'слово', 'случаться', 'слушать', 'слышать', 'смерть', 'сметь', 'смотреть', 'собственный', 'соглашаться', 'солнце', 'спасать', 'спать', 'спокойно', 'спокойствие', 'спрашивать', 'стадо', 'становиться', 'стараться', 'старуха', 'старушка', 'старый', 'статься', 'стена', 'сто', 'столь', 'стон', 'стонать', 'сторона', 'стоять', 'страшно', 'страшный', 'судьба', 'схватывать', 'счастие', 'счастливый', 'сын', 'таить', 'твой', 'темный', 'тения', 'тихий', 'тихонько', 'томный', 'трава', 'трепетать', 'трогать', 'убивать', 'уверять', 'увидеть', 'увидеться', 'удерживать', 'удивляться', 'удовольствие', 'узнавать', 'улица', 'улыбка', 'уметь', 'умирать', 'унылый', 'упасть', 'услышать', 'утешение', 'утро', 'хижина', 'хлеб', 'ходить', 'холм', 'хороший', 'хотеть', 'хотеться', 'хотя', 'худо', 'худой', 'царь', 'цветок', 'целовать', 'час', 'часто', 'человек', 'чистый', 'читатель', 'чувствительный', 'чувство', 'чувствовать', 'чудно', 'чулок', 'шестой', 'шум', 'шуметь', 'щадить', 'щека', 'эраст', 'эрастов', 'это']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1DAUZGxHNHU"
      },
      "source": [
        "Let's see what the model learned:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0x8fs7sHNHW",
        "outputId": "ff2c0582-be76-4f52-808a-323b2a57cdc0"
      },
      "source": [
        "model_liza.wv.most_similar(positive=[\"смерть\", \"любовь\"], negative=[\"печальный\"], topn=3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('хотеть', 0.25259149074554443),\n",
              " ('лиза', 0.23282110691070557),\n",
              " ('возвращаться', 0.22498047351837158)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhbn1Oa1HNHZ",
        "outputId": "2e89de05-0b75-45f3-884a-bbf3ec3f4981"
      },
      "source": [
        "model_liza.wv.most_similar(\"любовь\", topn=3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('лиза', 0.28875115513801575),\n",
              " ('свет', 0.27768391370773315),\n",
              " ('хотеть', 0.25997158885002136)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEd9n-70HNHg",
        "outputId": "43acd5ef-a5cc-446c-bcd0-acbe66c8ff29"
      },
      "source": [
        "model_liza.wv.similarity(\"лиза\", \"эраст\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3469555"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp-fhh_fHNHj",
        "outputId": "c71bab1b-ac95-41db-b2cf-5b2f48882a8c"
      },
      "source": [
        "model_liza.wv.similarity(\"лиза\", \"лиза\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gmr5iAcoHNHm",
        "outputId": "70dcb081-87c8-4f88-f4a4-69bd3f9dedd3"
      },
      "source": [
        "model_liza.wv.doesnt_match(\"скорбь грусть слеза улыбка\".split())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'слеза'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yGJRjeUHNHo",
        "outputId": "4e5a56fe-e93e-4147-8d73-3413a303f738"
      },
      "source": [
        "model_liza.wv.words_closer_than(\"лиза\", \"эраст\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['свой',\n",
              " 'мочь',\n",
              " 'который',\n",
              " 'сказать',\n",
              " 'ах',\n",
              " 'весь',\n",
              " 'любить',\n",
              " 'человек',\n",
              " 'день',\n",
              " 'чистый']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-hphDcEHNHq"
      },
      "source": [
        "#### Parameter variation\n",
        "\n",
        "Note that what is said below works for large corpora, if your corpus is small, you need to be extra careful!\n",
        "\n",
        "1) preprocessing -- do we lemmatize, tokenize, pos-tag or not\n",
        "\n",
        "2) corpus size -- the greater, the better; but! for semantic tasks the quality is more important than quantity\n",
        "\n",
        "3) vocabulary size\n",
        "\n",
        "4) negative samples\n",
        "\n",
        "5) the number of iterations\n",
        "\n",
        "6) vector size -- 100-300 (it looks like >300 does not make the results better)\n",
        "\n",
        "7) window size -- for syntax -- around 4, for semantics -- 8, 10.\n",
        "\n",
        "A paper that discusses different parameter settings: https://www.aclweb.org/anthology/D14-1162.pdf\n",
        "\n",
        "#### How to use a pre-trained model\n",
        "\n",
        "#### RusVectōrēs\n",
        "\n",
        "RusVectōrēs (https://rusvectores.org/ru/) provides a number of pre-trained models for Russian.\n",
        "\n",
        "For other languages, look at [fastText](https://fasttext.cc/docs/en/english-vectors.html) and [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
        "\n",
        "Let's also look at some vector novels https://nevmenandr.github.io/novel2vec/\n",
        "\n",
        "#### Working with a model\n",
        "\n",
        "Word2vec models can have two formats:\n",
        "\n",
        "+ .vec.gz — an ordinary file\n",
        "+ .bin.gz — a binary file\n",
        "\n",
        "To load a word2vec model, use `KeyedVectors`, you can set the `binary` parameter of the function `load_word2vec_format`.\n",
        "\n",
        "Note that if the embeddings were created not by word2vec, you need to use `load`. Use it if you load the `glove`, `fasttext`, `bpe` embeddings.\n",
        "\n",
        "Let's load a RusVectōrēs model for Russian, trained on Russian National Corpus 2015."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "filI-sL-HNHw",
        "outputId": "86ec21e5-39d2-4bc2-ef01-356bb93e9353"
      },
      "source": [
        "urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
              " <http.client.HTTPMessage at 0x7f3f16727c10>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dOL_0JDHNH0",
        "outputId": "b52c20ee-0bdc-4b3d-ae30-244d1298b1b0"
      },
      "source": [
        "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
        "\n",
        "if m.endswith('.vec.gz'):\n",
        "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
        "elif m.endswith('.bin.gz'):\n",
        "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
        "else:\n",
        "    model = gensim.models.KeyedVectors.load(m)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-09 11:10:47,492 : INFO : loading projection weights from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n",
            "2021-09-09 11:11:04,578 : INFO : loaded (281776, 300) matrix from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihw9StUmHNH3"
      },
      "source": [
        "words = ['хороший_A', 'плохой_A', 'ужасный_A','жуткий_A', 'страшный_A', 'красный_A', 'синий_A']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ltyT3lGHNH4"
      },
      "source": [
        "We need the POS tags, because the model was trained on lemmatized and tagged words. The name of the model specifies the algorythm that was used to tag the words, mystem, in our case.\n",
        "\n",
        "Let's look at the 10 closest members for each word that we are interested in and at the cosine similarity.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXU-NQA5HNH6",
        "outputId": "915cadf0-63b8-49a1-86be-764b0c84a2e8"
      },
      "source": [
        "for word in words:\n",
        "    # is the word present in the model?\n",
        "    if word in model:\n",
        "        print(word)\n",
        "        # looking at the first 10 numbers from the embedding \n",
        "        print(model[word][:10])\n",
        "        # getting 10 neighbours\n",
        "        for i in model.most_similar(positive=[word], topn=10):\n",
        "            # word + cosine similarity\n",
        "            print(i[0], i[1])\n",
        "        print('\\n')\n",
        "    else:\n",
        "        # Oops!\n",
        "        print('Oops, the word \"%s\" is not in the model!' % word)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-09 11:11:04,602 : INFO : precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хороший_A\n",
            "[ 0.00722357 -0.00361956  0.1272455   0.06584469  0.00709477 -0.02014845\n",
            " -0.02056034  0.01321563  0.13692418 -0.09624264]\n",
            "плохой_A 0.7463520765304565\n",
            "неплохой_A 0.6708558797836304\n",
            "отличный_A 0.6633436679840088\n",
            "превосходный_A 0.6079519987106323\n",
            "замечательный_A 0.586450457572937\n",
            "недурной_A 0.5322482585906982\n",
            "отменный_A 0.5168066024780273\n",
            "прекрасный_A 0.4982393980026245\n",
            "посредственный_A 0.49099433422088623\n",
            "приличный_A 0.48622459173202515\n",
            "\n",
            "\n",
            "плохой_A\n",
            "[-0.05218472  0.0307817   0.1459371   0.0151835   0.06219714  0.01153753\n",
            " -0.01169093  0.01818374  0.0955373  -0.10191503]\n",
            "хороший_A 0.7463520765304565\n",
            "дурной_A 0.6186875104904175\n",
            "скверный_A 0.6014161109924316\n",
            "отличный_A 0.5226833820343018\n",
            "посредственный_A 0.5061030983924866\n",
            "неважный_A 0.5021152496337891\n",
            "неплохой_A 0.49169060587882996\n",
            "никудышный_A 0.48035892844200134\n",
            "ухудшать_V 0.43680477142333984\n",
            "плохо_ADV 0.4314875304698944\n",
            "\n",
            "\n",
            "ужасный_A\n",
            "[-0.05553271 -0.03172469  0.01998607  0.00171507 -0.00935555 -0.0296017\n",
            "  0.05394973  0.01597532 -0.03785459 -0.02099892]\n",
            "страшный_A 0.8007251024246216\n",
            "жуткий_A 0.6982528567314148\n",
            "отвратительный_A 0.6798903942108154\n",
            "ужасающий_A 0.6174501180648804\n",
            "чудовищный_A 0.6100856065750122\n",
            "постыдный_A 0.6009703278541565\n",
            "невероятный_A 0.5827822685241699\n",
            "ужасать_V 0.5815353393554688\n",
            "кошмарный_A 0.5675790309906006\n",
            "позорный_A 0.5351496338844299\n",
            "\n",
            "\n",
            "жуткий_A\n",
            "[-0.07627533 -0.06143281 -0.02622319 -0.03769541 -0.00350412 -0.01479934\n",
            "  0.03325103  0.06712756 -0.0044996   0.0145266 ]\n",
            "ужасный_A 0.6982529163360596\n",
            "страшный_A 0.6917036771774292\n",
            "зловещий_A 0.6490101218223572\n",
            "странный_A 0.6009964942932129\n",
            "отвратительный_A 0.5856714248657227\n",
            "тоскливый_A 0.5783498287200928\n",
            "кошмарный_A 0.5670032501220703\n",
            "гнетущий_A 0.5607054829597473\n",
            "чудовищный_A 0.5550791025161743\n",
            "мрачный_A 0.5542315244674683\n",
            "\n",
            "\n",
            "страшный_A\n",
            "[-0.12759186 -0.0206753   0.00979353 -0.02963523  0.03109632  0.02121338\n",
            " -0.02869159  0.02574235 -0.02556899 -0.03742376]\n",
            "ужасный_A 0.8007251620292664\n",
            "жуткий_A 0.6917036175727844\n",
            "чудовищный_A 0.5934231877326965\n",
            "кошмарный_A 0.539563000202179\n",
            "отвратительный_A 0.5351147651672363\n",
            "невероятный_A 0.5207849144935608\n",
            "ужасающий_A 0.5174921154975891\n",
            "зловещий_A 0.5163233876228333\n",
            "жестокий_A 0.5096044540405273\n",
            "ужасать_V 0.5071669816970825\n",
            "\n",
            "\n",
            "красный_A\n",
            "[ 0.01627072 -0.01136785 -0.00790482  0.02294072  0.05129128  0.10162549\n",
            "  0.07488654 -0.06475785 -0.0203686   0.09159683]\n",
            "алый_A 0.6421287059783936\n",
            "малиновый_A 0.6113021373748779\n",
            "красная_S 0.5526680946350098\n",
            "желтый_A 0.5431625843048096\n",
            "оранжевый_A 0.5371882319450378\n",
            "трехцветный_A 0.5317935347557068\n",
            "пунцовый_A 0.5125025510787964\n",
            "синий_A 0.5102002024650574\n",
            "фиолетовый_A 0.5072877407073975\n",
            "лиловый_A 0.5004071593284607\n",
            "\n",
            "\n",
            "синий_A\n",
            "[-0.00614284  0.04970241 -0.00461786 -0.11465221  0.08177482  0.00020589\n",
            "  0.04895581  0.02750725 -0.05211812  0.06006202]\n",
            "голубой_A 0.855513334274292\n",
            "темно-синий_A 0.7498062252998352\n",
            "оранжевый_A 0.7341034412384033\n",
            "лиловый_A 0.7314398884773254\n",
            "фиолетовый_A 0.7291390895843506\n",
            "желтый_A 0.7263568639755249\n",
            "ярко-синий_A 0.699012815952301\n",
            "черный_A 0.690920889377594\n",
            "зеленый_A 0.6799379587173462\n",
            "коричневый_A 0.6729934215545654\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQleI2RSHNH-"
      },
      "source": [
        "Cosine similarity for a pair of words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7yCoODJHNH_",
        "outputId": "2f1f763d-3076-4c64-c1bd-bb09ceff9e3e"
      },
      "source": [
        "print(model.similarity('плохой_A', 'хороший_A'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.74635214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nj_YXxnHNIA",
        "outputId": "9ed02456-aaba-4c8e-f3ff-70627c2dd15d"
      },
      "source": [
        "print(model.similarity('плохой_A', 'синий_A'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.12778337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLh-SjvCHNIC",
        "outputId": "00738f89-5176-4e37-ce89-12c2585a89e7"
      },
      "source": [
        "print(model.similarity('ужасный_A', 'жуткий_A'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.69825286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URFKk_BAHNID"
      },
      "source": [
        "Proportion:\n",
        "\n",
        "+ positive — vectors that we add\n",
        "+ negative — vectors that we subtract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tAzDqJ6HNIF",
        "outputId": "0f0e1976-5a4c-49da-db25-d14ecc19af52"
      },
      "source": [
        "print(model.most_similar(positive=['плохой_A', 'ужасный_A'], negative=['хороший_A'])[0][0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "страшный_A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XApnxdg-HNIH"
      },
      "source": [
        "Find the word that does not match the rest of the words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzguX9wNHNIJ",
        "outputId": "fa612717-9535-43e8-abb3-fb842f650013"
      },
      "source": [
        "print(model.doesnt_match('плохой_A хороший_A ужасный_A страшный_A'.split()))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хороший_A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhEBxE72RiHq",
        "outputId": "e76e2051-2ff3-4362-aa63-4c367794f155"
      },
      "source": [
        "print(model.doesnt_match('плохой_A ужасный_A страшный_A'.split()))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "плохой_A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T15LhbeHNIK",
        "outputId": "63743d03-fc5e-48b8-eb35-6d35cfad4dac"
      },
      "source": [
        "for word, score in model.most_similar(positive=['ужасно_ADV'], negative=['плохой_A']):\n",
        "    print(f'{score:.4}\\t{word}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5575\tбезумно_ADV\n",
            "0.4791\tбезмерно_ADV\n",
            "0.4536\tжутко_ADV\n",
            "0.4472\tневероятно_ADV\n",
            "0.4394\tочень_ADV\n",
            "0.4364\tчертовски_ADV\n",
            "0.4231\tстрашно_ADV\n",
            "0.4124\tнеобычайно_ADV\n",
            "0.4119\tнестерпимо_ADV\n",
            "0.4005\tнеобыкновенно_ADV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSkRa57-HNIL"
      },
      "source": [
        "#### Visualization of the data\n",
        "\n",
        "Many ways to do it, let's try PCA (Principle Component Analysis, reduces the number of dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pma3tEUIHNIP"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRbvoXO6HNIR"
      },
      "source": [
        "words = ['хороший_A', 'плохой_A', 'ужасный_A','жуткий_A', 'страшный_A', 'красный_A', 'синий_A']\n",
        "X = model[words]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLaKrbL0HNIS"
      },
      "source": [
        "Executed on the list on words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAaUw52YHNIT"
      },
      "source": [
        "pca = PCA(n_components=2)\n",
        "coords = pca.fit_transform(X)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "gZuLUS_cHNIV",
        "outputId": "9fcfee22-661d-410e-d372-89633b6bc035"
      },
      "source": [
        "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
        "plt.title('Words')\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhg0QhpkHNIW"
      },
      "source": [
        "Executed on all the words in the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v_KJOWKHNIX"
      },
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca.fit(model[list(model.vocab)])\n",
        "coords = pca.transform(model[words])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Fv8mEKKhHNIZ",
        "outputId": "22203607-1e32-48f4-e278-47e2d08c3db3"
      },
      "source": [
        "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
        "plt.title('Words')\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxCO--ZnHNIh"
      },
      "source": [
        "#### Model evaluation\n",
        "\n",
        "+ word similarity, compare the results of the training with experimental results from human participants\n",
        "+ analogies:\n",
        "\n",
        "| слово 1    | слово 2    | отношение     | \n",
        "|------------|------------|---------------|\n",
        "| Россия     | Москва     | страна-столица| \n",
        "| Норвегия   | Осло       | страна-столица|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-J3_4SqHNIk"
      },
      "source": [
        "res = model.accuracy('ru_analogy_tagged.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obVy0EUSHNIm"
      },
      "source": [
        "for row in res[4]['incorrect'][:10]:\n",
        "    print('\\t'.join(row))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}